{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **DiningDossier: AI-Powered Restaurant Intelligence Tool**\n",
        "DiningDossier is an automated marketing intelligence tool designed to help digital agencies find, analyze, and pitch restaurant clients. It uses a three-stage pipeline to scrape live Google Maps data, analyze it using Google Gemini AI, and generate professional PDF \"Dossiers\" with actionable sales strategies."
      ],
      "metadata": {
        "id": "91-d_PXuESrh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Setup & Configuration\n",
        "\n",
        "This block installs the necessary Python libraries and sets up the environment. We use apify-client for scraping, langchain-google-genai to connect to Google's LLM, and fpdf to generate the final reports.\n",
        "\n",
        "\n",
        "\n",
        "**Key Libraries:**\n",
        "\n",
        "*   **apify-client:** Connects to the Apify platform to run the Google Maps scraper.\n",
        "*   **langchain-google-genai:** The interface for Google's Gemini models.\n",
        "*   **pydantic:** Ensures the AI output follows a strict, error-free JSON structure.\n",
        "*   **fpdf:** A library for creating PDF documents programmatically."
      ],
      "metadata": {
        "id": "9TrA5gTLEbC5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYmjr77TlvHY",
        "outputId": "ed11b181-5530-406e-c699-2703b7d151a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting apify-client\n",
            "  Downloading apify_client-2.4.1-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting langchain-google-genai\n",
            "  Downloading langchain_google_genai-4.2.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: langchain-core in /usr/local/lib/python3.12/dist-packages (1.2.9)\n",
            "Collecting fpdf\n",
            "  Downloading fpdf-1.7.2.tar.gz (39 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (1.2.1)\n",
            "Collecting apify-shared<3.0.0,>=2.1.0 (from apify-client)\n",
            "  Downloading apify_shared-2.2.0-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting colorama>=0.4.0 (from apify-client)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Collecting impit>=0.9.2 (from apify-client)\n",
            "  Downloading impit-0.11.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: more-itertools>=10.0.0 in /usr/local/lib/python3.12/dist-packages (from apify-client) (10.8.0)\n",
            "Collecting filetype<2.0.0,>=1.2.0 (from langchain-google-genai)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: google-genai<2.0.0,>=1.56.0 in /usr/local/lib/python3.12/dist-packages (from langchain-google-genai) (1.62.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain-google-genai) (2.12.3)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (0.6.9)\n",
            "Requirement already satisfied: packaging>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (26.0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (9.1.3)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (4.15.0)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (0.14.0)\n",
            "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain-google-genai) (4.12.1)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.47.0 in /usr/local/lib/python3.12/dist-packages (from google-auth[requests]<3.0.0,>=2.47.0->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (2.47.0)\n",
            "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain-google-genai) (0.28.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.28.1 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain-google-genai) (2.32.4)\n",
            "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain-google-genai) (15.0.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain-google-genai) (1.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain-google-genai) (1.3.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core) (3.0.0)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (3.11.7)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (1.0.0)\n",
            "Requirement already satisfied: xxhash>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (3.6.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (0.25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.0.0->langchain-google-genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.0.0->langchain-google-genai) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.0.0->langchain-google-genai) (0.4.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0.0,>=4.8.0->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (3.11)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (4.9.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (0.16.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.28.1->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.28.1->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (2.5.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (0.6.2)\n",
            "Downloading apify_client-2.4.1-py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m86.4/86.4 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_google_genai-4.2.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m66.5/66.5 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading apify_shared-2.2.0-py3-none-any.whl (16 kB)\n",
            "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading impit-0.11.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m41.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: fpdf\n",
            "  Building wheel for fpdf (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fpdf: filename=fpdf-1.7.2-py2.py3-none-any.whl size=40704 sha256=bd67855072e682329793529d31561c24d5cb322582a5b078ab3a864943c6ebfb\n",
            "  Stored in directory: /root/.cache/pip/wheels/6e/62/11/dc73d78e40a218ad52e7451f30166e94491be013a7850b5d75\n",
            "Successfully built fpdf\n",
            "Installing collected packages: fpdf, filetype, impit, colorama, apify-shared, apify-client, langchain-google-genai\n",
            "Successfully installed apify-client-2.4.1 apify-shared-2.2.0 colorama-0.4.6 filetype-1.2.0 fpdf-1.7.2 impit-0.11.0 langchain-google-genai-4.2.0\n"
          ]
        }
      ],
      "source": [
        "!pip install apify-client langchain-google-genai langchain-core fpdf python-dotenv\n",
        "\n",
        "import os\n",
        "import time\n",
        "from apify_client import ApifyClient\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from pydantic import BaseModel, Field\n",
        "from langchain_core.output_parsers import JsonOutputParser\n",
        "from fpdf import FPDF\n",
        "\n",
        "# API KEYS\n",
        "APIFY_TOKEN = \"apify_api_DQezwydHyOjkhvXEIjGCpNVdMINvHS22tsBe\"\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyDHZUNSyHKkQOWjk4Hl7wRcIQBAB4wGoyc\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Module 1: The Scraper (Data Collection)\n",
        "\n",
        "This function acts as the \"Scout.\" It sends a request to Apify's google-places-crawler to find restaurants in specific cities.\n",
        "\n",
        "**What it does:** It iterates through a list of cities, determining the correct country (Canada or Bangladesh) to ensure accurate search results.\n",
        "\n",
        "**Data Points:** It extracts critical operational data including:\n",
        "\n",
        "\n",
        "*   Review Count & Star Rating (to judge reputation).\n",
        "*   Phone Number & Website (to check for \"Digital Ghost\" status).\n",
        "*   Latest Reviews (raw text for the AI to analyze).\n",
        "\n",
        "\n",
        "**Why it matters:** This automates the manual process of searching Google Maps, saving hours of research time."
      ],
      "metadata": {
        "id": "kohLM8roFXr6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Module 1: The Scraper\n",
        "\n",
        "def scrape_restaurants(cities):\n",
        "    \"\"\"\n",
        "    Scrapes detailed data: Phone, Hours, Pricing, and Category.\n",
        "    \"\"\"\n",
        "    print(f\"--- Step 1: Scouting Locations in {cities} ---\")\n",
        "    client = ApifyClient(APIFY_TOKEN)\n",
        "\n",
        "    # Dynamic search query for Canada/Bangladesh support\n",
        "    search_queries = []\n",
        "    for city in cities:\n",
        "        suffix = \"Bangladesh\" if city.lower() == \"dhaka\" else \"Canada\"\n",
        "        search_queries.append(f\"restaurants in {city}, {suffix}\")\n",
        "\n",
        "    run_input = {\n",
        "        \"searchStringsArray\": search_queries,\n",
        "        \"maxCrawledPlacesPerSearch\": 5, # Keep low for testing\n",
        "        \"language\": \"en\",\n",
        "        \"zoom\": 14,\n",
        "        \"scrapeReviewerName\": False,\n",
        "        \"scrapeReviewerId\": False,\n",
        "        \"scrapeReviewerUrl\": False,\n",
        "        \"reviewsSort\": \"newest\",\n",
        "        \"reviewsCount\": 10 # Increased to get better \"Best Seller\" insights\n",
        "    }\n",
        "\n",
        "    print(\"Sending scout drones (API requests)...\")\n",
        "    run = client.actor(\"compass/crawler-google-places\").call(run_input=run_input)\n",
        "\n",
        "    dataset_items = client.dataset(run[\"defaultDatasetId\"]).list_items().items\n",
        "    cleaned_leads = []\n",
        "\n",
        "    for item in dataset_items:\n",
        "        if not item.get(\"title\"): continue\n",
        "\n",
        "        # Extracting the new detailed fields\n",
        "        cleaned_leads.append({\n",
        "            \"name\": item.get(\"title\"),\n",
        "            \"address\": item.get(\"address\"),\n",
        "            \"phone\": item.get(\"phoneUnformatted\", \"No Phone Found\"),\n",
        "            \"website\": item.get(\"website\", \"No Website\"),\n",
        "            \"rating\": item.get(\"totalScore\", 0),\n",
        "            \"review_count\": item.get(\"reviewsCount\", 0),\n",
        "            \"price_level\": item.get(\"price\", \"Unknown\"), # usually $, $$, or $$$\n",
        "            \"category\": item.get(\"categoryName\", \"General Restaurant\"),\n",
        "            \"opening_hours\": item.get(\"openingHours\", []), # Raw list, we'll let Gemini format it\n",
        "            \"reviews\": \" | \".join([r.get('text') for r in item.get(\"reviews\", []) if r.get('text')])\n",
        "        })\n",
        "\n",
        "    print(f\"-> Scraped {len(cleaned_leads)} raw leads with detailed intel.\")\n",
        "    return cleaned_leads"
      ],
      "metadata": {
        "id": "74NzYzoHmLbv"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Module 2: The Brain (AI Analysis)\n",
        "\n",
        "This module uses Google Gemini 3 Flash to analyze the raw data collected by the scraper. It transforms unstructured review text into structured marketing intelligence.\n",
        "\n",
        "\n",
        "*   **Pydantic Model (LeadDossier):** Defines exactly what fields we want the AI to generate (e.g., \"pain_point_title\", \"pitch_strategy\"). This prevents the AI from hallucinating random formats.\n",
        "*   **Prompt Engineering:** We assign the AI a persona (\"Elite Marketing Intelligence Officer\") and give it a mission:\n",
        "\n",
        "\n",
        "\n",
        "1.   **Infer USP:** Find what makes the restaurant special.\n",
        "2.   **Analyze Shortcomings:** Identify specific complaints (e.g., \"rude service,\" \"cold food\").\n",
        "\n",
        "3.  **Draft Strategy:** Create a custom cold-call opener based on those findings.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "*   **Gemini 3 Flash:** Chosen for its speed and ability to handle large context windows (processing up to 2000 characters of reviews).\n",
        "\n"
      ],
      "metadata": {
        "id": "sTkB30eLFwz-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Module 2: The Brain\n",
        "\n",
        "class LeadDossier(BaseModel):\n",
        "    summary: str = Field(description=\"2 sentence summary of business and vibe\")\n",
        "    cuisine_type: str = Field(description=\"Specific cuisine (e.g. 'Authentic Italian' or 'Fusion Burger')\")\n",
        "    pricing_category: str = Field(description=\"Estimated pricing: $, $$, or $$$ based on reviews/data\")\n",
        "    operating_hours_summary: str = Field(description=\"A concise summary of when they are open (e.g. 'Daily 9am-10pm')\")\n",
        "\n",
        "    usp: str = Field(description=\"Unique Selling Proposition: What customers say makes this place special\")\n",
        "    popular_dishes: str = Field(description=\"List of 3-4 most mentioned dishes in reviews\")\n",
        "\n",
        "    pain_point_title: str = Field(description=\"Short title for the problem (e.g. 'Service Bottlenecks')\")\n",
        "    detailed_shortcomings: str = Field(description=\"3-4 sentences explaining the specific complaints found in reviews\")\n",
        "\n",
        "    pitch_strategy: str = Field(description=\"Strategic advice on what service to pitch\")\n",
        "    cold_call_opener: str = Field(description=\"A conversational, high-impact opening pitch\")\n",
        "\n",
        "def analyze_lead(lead_data):\n",
        "    \"\"\"\n",
        "    Uses Gemini 3 Flash to infer complex details like USP and Popular Dishes.\n",
        "    \"\"\"\n",
        "    llm = ChatGoogleGenerativeAI(\n",
        "        model=\"gemini-3-flash-preview\",\n",
        "        temperature=0.3,\n",
        "    )\n",
        "    parser = JsonOutputParser(pydantic_object=LeadDossier)\n",
        "\n",
        "    prompt = ChatPromptTemplate.from_template(\n",
        "        \"\"\"\n",
        "        You are an elite Marketing Intelligence Officer.\n",
        "        Analyze this raw restaurant data to generate a detailed \"Tactical Dossier\".\n",
        "\n",
        "        RAW DATA:\n",
        "        Name: {name}\n",
        "        Category: {category}\n",
        "        Raw Price: {price_level}\n",
        "        Raw Hours: {opening_hours}\n",
        "        Reviews: {reviews}\n",
        "\n",
        "        YOUR MISSION:\n",
        "        1. **Infer the USP:** What do people love? (Ambiance? Specific dish? Speed?)\n",
        "        2. **Find Best Sellers:** Look for food items mentioned repeatedly in the reviews.\n",
        "        3. **Analyze Shortcomings:** Don't just say \"bad service.\" Be specific (e.g., \"Long wait times on weekends,\" \"Rude host,\" \"Cold food\").\n",
        "        4. **Format Hours:** Turn the raw opening hours list into a clean, 1-line summary.\n",
        "\n",
        "        Generate the dossier in strict JSON format.\n",
        "        {format_instructions}\n",
        "        \"\"\"\n",
        "    )\n",
        "\n",
        "    chain = prompt | llm | parser\n",
        "\n",
        "    # We pass more data to the LLM now\n",
        "    try:\n",
        "        print(f\"Analyzing {lead_data['name']}...\")\n",
        "        response = chain.invoke({\n",
        "            \"name\": lead_data['name'],\n",
        "            \"category\": lead_data['category'],\n",
        "            \"price_level\": lead_data['price_level'],\n",
        "            \"opening_hours\": str(lead_data['opening_hours']),\n",
        "            \"reviews\": lead_data['reviews'][:2000], # Increased context window for better analysis\n",
        "            \"format_instructions\": parser.get_format_instructions()\n",
        "        })\n",
        "        return response\n",
        "    except Exception as e:\n",
        "        print(f\"Error analyzing {lead_data['name']}: {e}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "qUWxkiu8mUnM"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Module 3: The Reporter (PDF Generation)\n",
        "\n",
        "The final stage takes the structured AI output and formats it into a professional, one-page PDF \"Dossier.\"\n",
        "\n",
        "\n",
        "*   **Data Visualization:** It organizes information into \"Operational Intel\" (left column) and \"Market Signature\" (right column) for easy reading.\n",
        "\n",
        "\n",
        "*   **Strategic Highlighting:**\n",
        "\n",
        "1.   **Red Text:** Used for the \"Warning Signal\" (Pain Points) to grab the client's attention.\n",
        "2.   **Blue Box:** Used for the \"Strategic Attack Plan\" to highlight the solution.\n",
        "\n",
        "\n",
        "**Text Cleaning:** Includes a clean() function to handle special characters (like emojis or accents) that can crash standard PDF generators."
      ],
      "metadata": {
        "id": "Oiobyfp9OsAC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Module 3: The Reporter\n",
        "\n",
        "def generate_pdf(lead, analysis):\n",
        "    \"\"\"\n",
        "    Generates a professional, detailed 1-page dossier.\n",
        "    \"\"\"\n",
        "    pdf = FPDF()\n",
        "    pdf.add_page()\n",
        "\n",
        "    # --- UPDATED CLEAN FUNCTION ---\n",
        "    def clean(text):\n",
        "        if not text: return \"N/A\"\n",
        "        text = str(text)\n",
        "\n",
        "        # 1. Replace \"Smart\" characters with \"Standard\" ones\n",
        "        text = text.replace('â€™', \"'\").replace('â€˜', \"'\")  # Fix apostrophes\n",
        "        text = text.replace('â€œ', '\"').replace('â€', '\"')  # Fix quotes\n",
        "        text = text.replace('â€“', '-').replace('â€”', '-')  # Fix dashes\n",
        "        text = text.replace('â€¦', '...')                  # Fix ellipses\n",
        "\n",
        "        # 2. Encode to Latin-1 to handle any remaining special characters\n",
        "        # Any TRULY weird characters (like emojis) will still become '?',\n",
        "        # but your text will now be readable.\n",
        "        return text.encode('latin-1', 'replace').decode('latin-1')\n",
        "    # ------------------------------\n",
        "\n",
        "    # --- HEADER SECTION ---\n",
        "    pdf.set_font(\"Arial\", 'B', 18)\n",
        "    pdf.cell(0, 10, txt=clean(lead['name'].upper()), ln=True, align='C')\n",
        "\n",
        "    pdf.set_font(\"Arial\", 'I', 10)\n",
        "    subtitle = f\"{analysis.get('cuisine_type')}  |  {analysis.get('pricing_category')}  |  {lead['rating']} Stars ({lead['review_count']} Reviews)\"\n",
        "    pdf.cell(0, 8, txt=clean(subtitle), ln=True, align='C')\n",
        "    pdf.line(10, 28, 200, 28)\n",
        "    pdf.ln(8)\n",
        "\n",
        "    # --- COLUMNS SETUP ---\n",
        "    col_width = 90\n",
        "    start_y = pdf.get_y()\n",
        "\n",
        "    # --- LEFT COLUMN: OPERATIONAL INTEL ---\n",
        "    pdf.set_font(\"Arial\", 'B', 12)\n",
        "    pdf.set_fill_color(230, 230, 230) # Light Gray Background\n",
        "    pdf.cell(col_width, 8, txt=\"  OPERATIONAL INTEL\", ln=True, fill=True)\n",
        "\n",
        "    pdf.set_font(\"Arial\", size=10)\n",
        "    pdf.ln(2)\n",
        "\n",
        "    # Address\n",
        "    pdf.set_font(\"Arial\", 'B', 10)\n",
        "    pdf.cell(20, 5, txt=\"Address: \")\n",
        "    pdf.set_font(\"Arial\", size=10)\n",
        "    pdf.multi_cell(70, 5, txt=clean(lead['address']))\n",
        "\n",
        "    # Phone\n",
        "    pdf.ln(2)\n",
        "    pdf.set_font(\"Arial\", 'B', 10)\n",
        "    pdf.cell(20, 5, txt=\"Phone: \")\n",
        "    pdf.set_font(\"Arial\", size=10)\n",
        "    pdf.cell(70, 5, txt=clean(lead['phone']), ln=True)\n",
        "\n",
        "    # Hours\n",
        "    pdf.ln(2)\n",
        "    pdf.set_font(\"Arial\", 'B', 10)\n",
        "    pdf.cell(20, 5, txt=\"Hours: \")\n",
        "    pdf.set_font(\"Arial\", size=10)\n",
        "    pdf.multi_cell(70, 5, txt=clean(analysis.get('operating_hours_summary')))\n",
        "\n",
        "    # Website\n",
        "    pdf.ln(2)\n",
        "    pdf.set_font(\"Arial\", 'B', 10)\n",
        "    pdf.cell(20, 5, txt=\"Website: \")\n",
        "    pdf.set_font(\"Arial\", size=10)\n",
        "    pdf.multi_cell(70, 5, txt=clean(lead['website']))\n",
        "\n",
        "    left_col_end_y = pdf.get_y()\n",
        "\n",
        "    # --- RIGHT COLUMN: MARKET POSITION ---\n",
        "    pdf.set_xy(110, start_y)\n",
        "    pdf.set_font(\"Arial\", 'B', 12)\n",
        "    pdf.cell(col_width, 8, txt=\"  MARKET SIGNATURE\", ln=True, fill=True)\n",
        "\n",
        "    pdf.ln(2)\n",
        "    pdf.set_x(110)\n",
        "    pdf.set_font(\"Arial\", 'B', 10)\n",
        "    pdf.cell(col_width, 5, txt=\"Unique Selling Proposition (USP):\", ln=True)\n",
        "    pdf.set_x(110)\n",
        "    pdf.set_font(\"Arial\", 'I', 10)\n",
        "    pdf.multi_cell(col_width, 5, txt=clean(analysis.get('usp')))\n",
        "\n",
        "    pdf.ln(3)\n",
        "    pdf.set_x(110)\n",
        "    pdf.set_font(\"Arial\", 'B', 10)\n",
        "    pdf.cell(col_width, 5, txt=\"Popular Dishes / Best Sellers:\", ln=True)\n",
        "    pdf.set_x(110)\n",
        "    pdf.set_font(\"Arial\", size=10)\n",
        "    pdf.multi_cell(col_width, 5, txt=clean(analysis.get('popular_dishes')))\n",
        "\n",
        "    max_y = max(left_col_end_y, pdf.get_y())\n",
        "    pdf.set_xy(10, max_y + 10)\n",
        "\n",
        "    # --- SECTION: DETAILED PAIN POINTS ---\n",
        "    pdf.set_font(\"Arial\", 'B', 12)\n",
        "    pdf.set_text_color(200, 0, 0) # Dark Red\n",
        "    pdf.cell(0, 8, txt=f\"  WARNING SIGNAL: {clean(analysis.get('pain_point_title'))}\", ln=True, fill=True)\n",
        "    pdf.set_text_color(0, 0, 0) # Reset color\n",
        "\n",
        "    pdf.ln(2)\n",
        "    pdf.set_font(\"Arial\", size=10)\n",
        "    pdf.multi_cell(0, 5, txt=clean(analysis.get('detailed_shortcomings')))\n",
        "\n",
        "    pdf.ln(5)\n",
        "\n",
        "    # --- SECTION: STRATEGIC ATTACK PLAN ---\n",
        "    pdf.set_font(\"Arial\", 'B', 12)\n",
        "    pdf.set_fill_color(230, 240, 255) # Light Blue\n",
        "    pdf.cell(0, 8, txt=\"  STRATEGIC ATTACK PLAN\", ln=True, fill=True)\n",
        "\n",
        "    pdf.ln(3)\n",
        "    pdf.set_font(\"Arial\", 'B', 10)\n",
        "    pdf.cell(0, 5, txt=\"Suggested Pitch Strategy:\", ln=True)\n",
        "    pdf.set_font(\"Arial\", size=10)\n",
        "    pdf.multi_cell(0, 5, txt=clean(analysis.get('pitch_strategy')))\n",
        "\n",
        "    pdf.ln(3)\n",
        "    pdf.set_font(\"Arial\", 'B', 10)\n",
        "    pdf.cell(0, 5, txt=\"Golden Cold Call Opener:\", ln=True)\n",
        "    pdf.set_font(\"Arial\", 'I', 10)\n",
        "    pdf.multi_cell(0, 5, txt=f\"\\\"{clean(analysis.get('cold_call_opener'))}\\\"\")\n",
        "\n",
        "    # Save\n",
        "    safe_name = \"\".join([c for c in lead['name'] if c.isalnum()]).strip()\n",
        "    filename = f\"Detailed_Dossier_{safe_name}.pdf\"\n",
        "    pdf.output(filename)\n",
        "    print(f\"-> Generated Report: {filename}\")"
      ],
      "metadata": {
        "id": "lxObD8WzxZ9i"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Main Execution Loop\n",
        "\n",
        "This is the entry point of the script. It orchestrates the entire pipeline.\n",
        "\n",
        "**Workflow:**\n",
        "\n",
        "*   Define the **target cities**.\n",
        "*   Call **scrape_restaurants** to get the raw leads.\n",
        "*   Loop through each lead and pass it to **analyze_lead**.\n",
        "*   If analysis is successful, pass the result to **generate_pdf**.\n",
        "*   **Rate Limiting:** Includes a time.sleep(2) pause to respect API rate limits and prevent errors."
      ],
      "metadata": {
        "id": "DbOwzp6EPZZr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The main loop\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    import time\n",
        "\n",
        "    # 1. Define Targets\n",
        "    TARGET_CITIES = [\"Oshawa\", \"Toronto\", \"Dhaka\", \"Vancouver\"]\n",
        "\n",
        "    # 2. Scrape Data\n",
        "    raw_leads = scrape_restaurants(TARGET_CITIES)\n",
        "\n",
        "    # 3. Process\n",
        "    if not raw_leads:\n",
        "        print(\"No leads found.\")\n",
        "    else:\n",
        "        for lead in raw_leads:\n",
        "            time.sleep(2) # Safety pause\n",
        "            dossier = analyze_lead(lead)\n",
        "            if dossier:\n",
        "                generate_pdf(lead, dossier)\n",
        "\n",
        "    print(\"\\n--- MISSION ACCOMPLISHED ---\")"
      ],
      "metadata": {
        "id": "PwSOQV8muR76",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "114d5f97-cf77-48bd-aa60-6aee43595ace"
      },
      "execution_count": 5,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Step 1: Scouting Locations in ['Oshawa', 'Toronto', 'Dhaka', 'Vancouver'] ---\n",
            "Sending scout drones (API requests)...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m[apify.crawler-google-places runId:P9ht3nIjo2YNI6IO0]\u001b[0m -> Status: RUNNING, Message: \n",
            "\u001b[36m[apify.crawler-google-places runId:P9ht3nIjo2YNI6IO0]\u001b[0m -> 2026-02-17T01:51:43.296Z ACTOR: Pulling container image of build QMYVjsVD4Z8cVbb8j from registry.\n",
            "\u001b[36m[apify.crawler-google-places runId:P9ht3nIjo2YNI6IO0]\u001b[0m -> 2026-02-17T01:51:43.297Z ACTOR: Creating container.\n",
            "\u001b[36m[apify.crawler-google-places runId:P9ht3nIjo2YNI6IO0]\u001b[0m -> 2026-02-17T01:51:43.348Z ACTOR: Starting container.\n",
            "\u001b[36m[apify.crawler-google-places runId:P9ht3nIjo2YNI6IO0]\u001b[0m -> 2026-02-17T01:51:43.349Z ACTOR: Running under \"LIMITED_PERMISSIONS\" permission level.\n",
            "\u001b[36m[apify.crawler-google-places runId:P9ht3nIjo2YNI6IO0]\u001b[0m -> 2026-02-17T01:51:44.839Z \u001b[32mINFO\u001b[39m  System info\u001b[90m {\"apifyVersion\":\"3.5.1\",\"apifyClientVersion\":\"2.19.0\",\"crawleeVersion\":\"3.14.1\",\"osType\":\"Linux\",\"nodeVersion\":\"v18.20.8\"}\u001b[39m\n",
            "\u001b[36m[apify.crawler-google-places runId:P9ht3nIjo2YNI6IO0]\u001b[0m -> 2026-02-17T01:51:45.291Z \u001b[32mINFO\u001b[39m  ðŸ“¡ Geolocation started\n",
            "\u001b[36m[apify.crawler-google-places runId:P9ht3nIjo2YNI6IO0]\u001b[0m -> 2026-02-17T01:51:45.323Z \u001b[32mINFO\u001b[39m  ðŸ“¡ Geolocation finished\n",
            "\u001b[36m[apify.crawler-google-places runId:P9ht3nIjo2YNI6IO0]\u001b[0m -> 2026-02-17T01:51:45.428Z \u001b[32mINFO\u001b[39m  [BG ENQUEUE] Finished enqueueing\n",
            "\u001b[36m[apify.crawler-google-places runId:P9ht3nIjo2YNI6IO0]\u001b[0m -> Status: RUNNING, Message: Starting the crawler.\n",
            "\u001b[36m[apify.crawler-google-places runId:P9ht3nIjo2YNI6IO0]\u001b[0m -> 2026-02-17T01:51:45.576Z \u001b[32mINFO\u001b[39m \u001b[33m HttpCrawler:\u001b[39m Starting the crawler.\n",
            "\u001b[36m[apify.crawler-google-places runId:P9ht3nIjo2YNI6IO0]\u001b[0m -> 2026-02-17T01:51:48.489Z \u001b[32mINFO\u001b[39m  [CONSENT SCREEN] https://www.google.com/maps/search/restaurants%20in%20Toronto,%20Canada?hl=en\n",
            "\u001b[36m[apify.crawler-google-places runId:P9ht3nIjo2YNI6IO0]\u001b[0m -> 2026-02-17T01:51:48.490Z \u001b[32mINFO\u001b[39m  [CONSENT SCREEN] found bl: boq_identityfrontenduiserver_20260215.09_p0\n",
            "\u001b[36m[apify.crawler-google-places runId:P9ht3nIjo2YNI6IO0]\u001b[0m -> 2026-02-17T01:51:49.158Z \u001b[33mWARN\u001b[39m \u001b[33m HttpCrawler:\u001b[39m Reclaiming failed request back to the list or queue. Found place (https://www.google.com/maps/search/?api=1&query=Baxters%20Landing&query_place_id=ChIJ71ijPAEd1YkRfObkWsX2eSA) that's more than 2 500km away from search center. Retrying\n",
            "\u001b[36m[apify.crawler-google-places runId:P9ht3nIjo2YNI6IO0]\u001b[0m -> 2026-02-17T01:51:49.159Z     at checkForUnrelatedPlaces (file:///usr/src/app/dist/src/utils/places-enqueueing.js:187:19)\u001b[90m {\"id\":\"TnMn4eQ3PwbeFFQ\",\"url\":\"https://www.google.com/maps/search/restaurants%20in%20Oshawa,%20Canada?hl=en\",\"retryCount\":1}\u001b[39m\n",
            "\u001b[36m[apify.crawler-google-places runId:P9ht3nIjo2YNI6IO0]\u001b[0m -> 2026-02-17T01:51:52.874Z \u001b[33mWARN\u001b[39m \u001b[33m HttpCrawler:\u001b[39m Reclaiming failed request back to the list or queue. Found place (https://www.google.com/maps/search/?api=1&query=Yumi%20at%20Sheraton%20Dhaka&query_place_id=ChIJY4LXWcvHVTcR_nqOaCwb5qo) that's more than 2 500km away from search center. Retrying\n",
            "\u001b[36m[apify.crawler-google-places runId:P9ht3nIjo2YNI6IO0]\u001b[0m -> 2026-02-17T01:51:52.874Z     at checkForUnrelatedPlaces (file:///usr/src/app/dist/src/utils/places-enqueueing.js:187:19)\u001b[90m {\"id\":\"HAqdAta0eEvSyRQ\",\"url\":\"https://www.google.com/maps/search/restaurants%20in%20Dhaka,%20Bangladesh?hl=en\",\"retryCount\":1}\u001b[39m\n",
            "\u001b[36m[apify.crawler-google-places runId:P9ht3nIjo2YNI6IO0]\u001b[0m -> Status: RUNNING, Message: Scraped in total 0 search pages.\n",
            "\u001b[36m[apify.crawler-google-places runId:P9ht3nIjo2YNI6IO0]\u001b[0m -> 2026-02-17T01:51:55.577Z \u001b[32mINFO\u001b[39m  Scraped in total 0 search pages.\n",
            "\u001b[36m[apify.crawler-google-places runId:P9ht3nIjo2YNI6IO0]\u001b[0m -> 2026-02-17T01:51:56.512Z \u001b[33mWARN\u001b[39m \u001b[33m HttpCrawler:\u001b[39m Reclaiming failed request back to the list or queue. Found place (https://www.google.com/maps/search/?api=1&query=Richmond%20Station&query_place_id=ChIJJZP2IzPL1IkRoIXM5dEE9ck) that's more than 2 500km away from search center. Retrying\n",
            "\u001b[36m[apify.crawler-google-places runId:P9ht3nIjo2YNI6IO0]\u001b[0m -> 2026-02-17T01:51:56.513Z     at checkForUnrelatedPlaces (file:///usr/src/app/dist/src/utils/places-enqueueing.js:187:19)\u001b[90m {\"id\":\"JLVd9kd9AizSJ6y\",\"url\":\"https://www.google.com/maps/search/restaurants%20in%20Toronto,%20Canada?hl=en\",\"retryCount\":1}\u001b[39m\n",
            "\u001b[36m[apify.crawler-google-places runId:P9ht3nIjo2YNI6IO0]\u001b[0m -> 2026-02-17T01:51:57.429Z \u001b[33mWARN\u001b[39m \u001b[33m HttpCrawler:\u001b[39m Reclaiming failed request back to the list or queue. Found place (https://www.google.com/maps/search/?api=1&query=Blue%20Water%20Cafe&query_place_id=ChIJZ04tZ9ZzhlQRDsJZp_cOS4U) that's more than 2 500km away from search center. Retrying\n",
            "\u001b[36m[apify.crawler-google-places runId:P9ht3nIjo2YNI6IO0]\u001b[0m -> 2026-02-17T01:51:57.430Z     at checkForUnrelatedPlaces (file:///usr/src/app/dist/src/utils/places-enqueueing.js:187:19)\u001b[90m {\"id\":\"nNQq5ctPHBJytUE\",\"url\":\"https://www.google.com/maps/search/restaurants%20in%20Vancouver,%20Canada?hl=en\",\"retryCount\":1}\u001b[39m\n",
            "\u001b[36m[apify.crawler-google-places runId:P9ht3nIjo2YNI6IO0]\u001b[0m -> 2026-02-17T01:51:59.657Z \u001b[32mINFO\u001b[39m  [CONSENT SCREEN] https://www.google.com/maps/search/restaurants%20in%20Oshawa,%20Canada?hl=en\n",
            "\u001b[36m[apify.crawler-google-places runId:P9ht3nIjo2YNI6IO0]\u001b[0m -> 2026-02-17T01:51:59.658Z \u001b[32mINFO\u001b[39m  [CONSENT SCREEN] found bl: boq_identityfrontenduiserver_20260215.09_p0\n",
            "\u001b[36m[apify.crawler-google-places runId:P9ht3nIjo2YNI6IO0]\u001b[0m -> 2026-02-17T01:52:00.255Z \u001b[33mWARN\u001b[39m \u001b[33m HttpCrawler:\u001b[39m Reclaiming failed request back to the list or queue. Found place (https://www.google.com/maps/search/?api=1&query=Prego&query_place_id=ChIJiW7FHobHVTcRdOZQ3TwdSlk) that's more than 2 500km away from search center. Retrying\n",
            "\u001b[36m[apify.crawler-google-places runId:P9ht3nIjo2YNI6IO0]\u001b[0m -> 2026-02-17T01:52:00.256Z     at checkForUnrelatedPlaces (file:///usr/src/app/dist/src/utils/places-enqueueing.js:187:19)\u001b[90m {\"id\":\"HAqdAta0eEvSyRQ\",\"url\":\"https://www.google.com/maps/search/restaurants%20in%20Dhaka,%20Bangladesh?hl=en\",\"retryCount\":2}\u001b[39m\n",
            "\u001b[36m[apify.crawler-google-places runId:P9ht3nIjo2YNI6IO0]\u001b[0m -> 2026-02-17T01:52:03.892Z \u001b[33mWARN\u001b[39m \u001b[33m HttpCrawler:\u001b[39m Reclaiming failed request back to the list or queue. Found place (https://www.google.com/maps/search/?api=1&query=Black%2BBlue&query_place_id=ChIJ243-C381K4gRHMKWCGU86iM) that's more than 2 500km away from search center. Retrying\n",
            "\u001b[36m[apify.crawler-google-places runId:P9ht3nIjo2YNI6IO0]\u001b[0m -> 2026-02-17T01:52:03.893Z     at checkForUnrelatedPlaces (file:///usr/src/app/dist/src/utils/places-enqueueing.js:187:19)\u001b[90m {\"id\":\"JLVd9kd9AizSJ6y\",\"url\":\"https://www.google.com/maps/search/restaurants%20in%20Toronto,%20Canada?hl=en\",\"retryCount\":2}\u001b[39m\n",
            "\u001b[36m[apify.crawler-google-places runId:P9ht3nIjo2YNI6IO0]\u001b[0m -> 2026-02-17T01:52:05.501Z \u001b[32mINFO\u001b[39m  [Status message]: You can check all currently scraped places laid out on a map on: https://api.apify.com/v2/key-value-stores/z28rJa2kQXanxP2F0/records/results-map?signature=1KEAQtUzDn93tsl3G6flm\n",
            "\u001b[36m[apify.crawler-google-places runId:P9ht3nIjo2YNI6IO0]\u001b[0m -> 2026-02-17T01:52:05.578Z \u001b[32mINFO\u001b[39m  Scraped in total 0 search pages.\n",
            "\u001b[36m[apify.crawler-google-places runId:P9ht3nIjo2YNI6IO0]\u001b[0m -> 2026-02-17T01:52:06.847Z \u001b[33mWARN\u001b[39m \u001b[33m HttpCrawler:\u001b[39m Reclaiming failed request back to the list or queue. Found place (https://www.google.com/maps/search/?api=1&query=Baxters%20Landing&query_place_id=ChIJ71ijPAEd1YkRfObkWsX2eSA) that's more than 2 500km away from search center. Retrying\n",
            "\u001b[36m[apify.crawler-google-places runId:P9ht3nIjo2YNI6IO0]\u001b[0m -> 2026-02-17T01:52:06.848Z     at checkForUnrelatedPlaces (file:///usr/src/app/dist/src/utils/places-enqueueing.js:187:19)\u001b[90m {\"id\":\"TnMn4eQ3PwbeFFQ\",\"url\":\"https://www.google.com/maps/search/restaurants%20in%20Oshawa,%20Canada?hl=en\",\"retryCount\":2}\u001b[39m\n",
            "\u001b[36m[apify.crawler-google-places runId:P9ht3nIjo2YNI6IO0]\u001b[0m -> 2026-02-17T01:52:07.229Z \u001b[33mWARN\u001b[39m \u001b[33m HttpCrawler:\u001b[39m Reclaiming failed request back to the list or queue. Found place (https://www.google.com/maps/search/?api=1&query=Prego&query_place_id=ChIJiW7FHobHVTcRdOZQ3TwdSlk) that's more than 2 500km away from search center. Retrying\n",
            "\u001b[36m[apify.crawler-google-places runId:P9ht3nIjo2YNI6IO0]\u001b[0m -> 2026-02-17T01:52:07.229Z     at checkForUnrelatedPlaces (file:///usr/src/app/dist/src/utils/places-enqueueing.js:187:19)\u001b[90m {\"id\":\"HAqdAta0eEvSyRQ\",\"url\":\"https://www.google.com/maps/search/restaurants%20in%20Dhaka,%20Bangladesh?hl=en\",\"retryCount\":3}\u001b[39m\n",
            "\u001b[36m[apify.crawler-google-places runId:P9ht3nIjo2YNI6IO0]\u001b[0m -> 2026-02-17T01:52:08.285Z \u001b[32mINFO\u001b[39m  ðŸ” [restaurants in Vancouver, Canada][38.4477|-122.6715][SCROLL: 2]: Search page scraped: 5 unique, 40 seen, 2 paginations, 35 reachedMaxResults. No more places found on this page. (no next cursor) --- https://www.google.com/maps/search/restaurants%20in%20Vancouver,%20Canada?hl=en\n",
            "\u001b[36m[apify.crawler-google-places runId:P9ht3nIjo2YNI6IO0]\u001b[0m -> 2026-02-17T01:52:11.874Z \u001b[33mWARN\u001b[39m \u001b[33m HttpCrawler:\u001b[39m Reclaiming failed request back to the list or queue. Found place (https://www.google.com/maps/search/?api=1&query=Black%2BBlue&query_place_id=ChIJ243-C381K4gRHMKWCGU86iM) that's more than 2 500km away from search center. Retrying\n",
            "\u001b[36m[apify.crawler-google-places runId:P9ht3nIjo2YNI6IO0]\u001b[0m -> 2026-02-17T01:52:11.875Z     at checkForUnrelatedPlaces (file:///usr/src/app/dist/src/utils/places-enqueueing.js:187:19)\u001b[90m {\"id\":\"JLVd9kd9AizSJ6y\",\"url\":\"https://www.google.com/maps/search/restaurants%20in%20Toronto,%20Canada?hl=en\",\"retryCount\":3}\u001b[39m\n",
            "\u001b[36m[apify.crawler-google-places runId:P9ht3nIjo2YNI6IO0]\u001b[0m -> 2026-02-17T01:52:15.578Z \u001b[32mINFO\u001b[39m  Scraped in total 1 search pages. Found 5 new places in the last 1 search pages (5.00 places per search page). Average capture rate can drop over the course of the Actor run.\n",
            "\u001b[36m[apify.crawler-google-places runId:P9ht3nIjo2YNI6IO0]\u001b[0m -> 2026-02-17T01:52:15.721Z \u001b[32mINFO\u001b[39m  ðŸ” [restaurants in Oshawa, Canada][38.0034|-79.4209][SCROLL: 2]: Search page scraped: 5 unique, 40 seen, 2 paginations, 35 reachedMaxResults. No more places found on this page. (no next cursor) --- https://www.google.com/maps/search/restaurants%20in%20Oshawa,%20Canada?hl=en\n",
            "\u001b[36m[apify.crawler-google-places runId:P9ht3nIjo2YNI6IO0]\u001b[0m -> Status: RUNNING, Message: Scraped in total 1 search pages. Found 5 new places in the last 1 search pages (5.00 places per search page). Average capture rate can drop over the course of the Actor run.\n",
            "\u001b[36m[apify.crawler-google-places runId:P9ht3nIjo2YNI6IO0]\u001b[0m -> 2026-02-17T01:52:16.298Z \u001b[32mINFO\u001b[39m  ðŸ” [restaurants in Dhaka, Bangladesh][38.4477|-122.6715][SCROLL: 2]: Search page scraped: 5 unique, 29 seen, 2 paginations, 24 reachedMaxResults. No more places found on this page. (no next cursor) --- https://www.google.com/maps/search/restaurants%20in%20Dhaka,%20Bangladesh?hl=en\n",
            "\u001b[36m[apify.crawler-google-places runId:P9ht3nIjo2YNI6IO0]\u001b[0m -> Status: RUNNING, Message: Finishing scraping because we reached max results --- https://www.google.com/maps/search/restaurants%20in%20Toronto,%20Canada?hl=en\n",
            "\u001b[36m[apify.crawler-google-places runId:P9ht3nIjo2YNI6IO0]\u001b[0m -> 2026-02-17T01:52:18.905Z \u001b[32mINFO\u001b[39m  [Status message]: Finishing scraping because we reached max results --- https://www.google.com/maps/search/restaurants%20in%20Toronto,%20Canada?hl=en\n",
            "\u001b[36m[apify.crawler-google-places runId:P9ht3nIjo2YNI6IO0]\u001b[0m -> 2026-02-17T01:52:24.097Z \u001b[32mINFO\u001b[39m \u001b[33m HttpCrawler:\u001b[39m Final request statistics:\u001b[90m {\"requestsFinished\":3,\"requestsFailed\":0,\"retryHistogram\":[null,1,1,1],\"requestAvgFailedDurationMillis\":null,\"requestAvgFinishedDurationMillis\":4830,\"requestsFinishedPerMinute\":5,\"requestsFailedPerMinute\":0,\"requestTotalDurationMillis\":14489,\"requestsTotal\":3,\"crawlerRuntimeMillis\":38738}\u001b[39m\n",
            "\u001b[36m[apify.crawler-google-places runId:P9ht3nIjo2YNI6IO0]\u001b[0m -> 2026-02-17T01:52:24.098Z \u001b[32mINFO\u001b[39m \u001b[33m HttpCrawler:\u001b[39m Finished! Total 3 requests: 3 succeeded, 0 failed.\u001b[90m {\"terminal\":true}\u001b[39m\n",
            "\u001b[36m[apify.crawler-google-places runId:P9ht3nIjo2YNI6IO0]\u001b[0m -> 2026-02-17T01:52:24.218Z \u001b[32mINFO\u001b[39m  ðŸ“Š 20 places scraped | unique: 20 | seen: 309 | searchPages: 3 | paginations: 16 | reachedMaxResults: 109\n",
            "\u001b[36m[apify.crawler-google-places runId:P9ht3nIjo2YNI6IO0]\u001b[0m -> 2026-02-17T01:52:24.379Z \u001b[32mINFO\u001b[39m  ðŸ“Š 20 places scraped | unique: 20 | seen: 309 | searchPages: 3 | paginations: 16 | reachedMaxResults: 109\n",
            "\u001b[36m[apify.crawler-google-places runId:P9ht3nIjo2YNI6IO0]\u001b[0m -> Status: RUNNING, Message: Scraping finished. You can view all scraped places laid out on a map on: https://api.apify.com/v2/key-value-stores/z28rJa2kQXanxP2F0/records/results-map?signature=1KEAQtUzDn93tsl3G6flm. It can take some time to fully load for large datasets.\n",
            "\u001b[36m[apify.crawler-google-places runId:P9ht3nIjo2YNI6IO0]\u001b[0m -> 2026-02-17T01:52:24.380Z \u001b[32mINFO\u001b[39m  [Status message]: Scraping finished. You can view all scraped places laid out on a map on: https://api.apify.com/v2/key-value-stores/z28rJa2kQXanxP2F0/records/results-map?signature=1KEAQtUzDn93tsl3G6flm. It can take some time to fully load for large datasets.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-> Scraped 20 raw leads with detailed intel.\n",
            "Analyzing Blue Water Cafe...\n",
            "-> Generated Report: Detailed_Dossier_BlueWaterCafe.pdf\n",
            "Analyzing Riley's Fish & Steak...\n",
            "-> Generated Report: Detailed_Dossier_RileysFishSteak.pdf\n",
            "Analyzing Coast...\n",
            "Error analyzing Coast: Error calling model 'gemini-3-flash-preview' (RESOURCE_EXHAUSTED): 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-3-flash\\nPlease retry in 56.054888779s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-3-flash', 'location': 'global'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '56s'}]}}\n",
            "Analyzing Joe Fortes Seafood & Chop House...\n",
            "-> Generated Report: Detailed_Dossier_JoeFortesSeafoodChopHouse.pdf\n",
            "Analyzing Black+Blue...\n",
            "-> Generated Report: Detailed_Dossier_BlackBlue.pdf\n",
            "Analyzing Baxters Landing...\n",
            "Error analyzing Baxters Landing: Error calling model 'gemini-3-flash-preview' (RESOURCE_EXHAUSTED): 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-3-flash\\nPlease retry in 615.526972ms.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-3-flash', 'location': 'global'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '0s'}]}}\n",
            "Analyzing Friendly Fox Restaurant + Bar...\n",
            "Error analyzing Friendly Fox Restaurant + Bar: Error calling model 'gemini-3-flash-preview' (RESOURCE_EXHAUSTED): 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-3-flash\\nPlease retry in 24.3592225s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-3-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '24s'}]}}\n",
            "Analyzing Simply South Oshawa | Indian Restaurant & Bar...\n",
            "Error analyzing Simply South Oshawa | Indian Restaurant & Bar: Error calling model 'gemini-3-flash-preview' (RESOURCE_EXHAUSTED): 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-3-flash\\nPlease retry in 47.506766468s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-3-flash', 'location': 'global'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '47s'}]}}\n",
            "Analyzing Wildfire Steakhouse Oshawa...\n",
            "Error analyzing Wildfire Steakhouse Oshawa: Error calling model 'gemini-3-flash-preview' (RESOURCE_EXHAUSTED): 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-3-flash\\nPlease retry in 9.958601141s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-3-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '9s'}]}}\n",
            "Analyzing Kelseys Original Roadhouse...\n",
            "Error analyzing Kelseys Original Roadhouse: Error calling model 'gemini-3-flash-preview' (RESOURCE_EXHAUSTED): 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-3-flash\\nPlease retry in 34.87201601s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-3-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '34s'}]}}\n",
            "Analyzing Prego...\n",
            "Error analyzing Prego: Error calling model 'gemini-3-flash-preview' (RESOURCE_EXHAUSTED): 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-3-flash\\nPlease retry in 58.700892574s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-3-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '58s'}]}}\n",
            "Analyzing The Garden Kitchen at Sheraton Dhaka...\n",
            "Error analyzing The Garden Kitchen at Sheraton Dhaka: Error calling model 'gemini-3-flash-preview' (RESOURCE_EXHAUSTED): 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-3-flash\\nPlease retry in 22.504841269s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-3-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '22s'}]}}\n",
            "Analyzing Yumi at Sheraton Dhaka...\n",
            "Error analyzing Yumi at Sheraton Dhaka: Error calling model 'gemini-3-flash-preview' (RESOURCE_EXHAUSTED): 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-3-flash\\nPlease retry in 45.753685148s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-3-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '45s'}]}}\n",
            "Analyzing Attitude Restaurant at Holiday Inn Dhaka City Centre...\n",
            "Error analyzing Attitude Restaurant at Holiday Inn Dhaka City Centre: Error calling model 'gemini-3-flash-preview' (RESOURCE_EXHAUSTED): 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-3-flash\\nPlease retry in 9.466633547s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-3-flash', 'location': 'global'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '9s'}]}}\n",
            "Analyzing Aquadeck at InterContinental Dhaka...\n",
            "Error analyzing Aquadeck at InterContinental Dhaka: Error calling model 'gemini-3-flash-preview' (RESOURCE_EXHAUSTED): 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-3-flash\\nPlease retry in 33.260151511s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-3-flash', 'location': 'global'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '33s'}]}}\n",
            "Analyzing Black+Blue...\n",
            "Error analyzing Black+Blue: Error calling model 'gemini-3-flash-preview' (RESOURCE_EXHAUSTED): 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-3-flash\\nPlease retry in 56.839108054s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-3-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '56s'}]}}\n",
            "Analyzing KÅŒST...\n",
            "Error analyzing KÅŒST: Error calling model 'gemini-3-flash-preview' (RESOURCE_EXHAUSTED): 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-3-flash\\nPlease retry in 20.432365963s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-3-flash', 'location': 'global'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '20s'}]}}\n",
            "Analyzing JOEY King St...\n",
            "Error analyzing JOEY King St: Error calling model 'gemini-3-flash-preview' (RESOURCE_EXHAUSTED): 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-3-flash\\nPlease retry in 42.9287596s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-3-flash', 'location': 'global'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '42s'}]}}\n",
            "Analyzing Byblos Downtown...\n",
            "Error analyzing Byblos Downtown: Error calling model 'gemini-3-flash-preview' (RESOURCE_EXHAUSTED): 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-3-flash\\nPlease retry in 5.849885425s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-3-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '5s'}]}}\n",
            "Analyzing Richmond Station...\n",
            "Error analyzing Richmond Station: Error calling model 'gemini-3-flash-preview' (RESOURCE_EXHAUSTED): 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-3-flash\\nPlease retry in 28.878542086s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-3-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '28s'}]}}\n",
            "\n",
            "--- MISSION ACCOMPLISHED ---\n"
          ]
        }
      ]
    }
  ]
}